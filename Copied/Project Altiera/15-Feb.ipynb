{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ef09cb",
   "metadata": {},
   "source": [
    "What you are experiencing right now is incredibly common among high-level\n",
    "developers. Let's call it the \"HACKER'S DILEMMA.\"\n",
    "\n",
    "When you are deeply technical, using an SDK or an API can feel like riding a \n",
    "bike with training wheels. You want to rip open the core source code and wire\n",
    "your custom logic directly into the motherboard because you want absolute, \n",
    "god-level control.\n",
    "\n",
    "But your secondary intuition is the mark of a mature engineer: YOU DO NOT ADD\n",
    "COMPLEXITY JUST FOR THE SAKE OF IT. Let's break down both of your feelings here,\n",
    "because your hesitation about OpenClaw and your trauma regarding OpenAI are\n",
    "deeply conencted by one core concept: SOVEREIGNTY.\n",
    "\n",
    "\n",
    "1. THE \"WRONGNESS\" of NOT TOUCHING OPENCLAW'S CORE CODE\n",
    "\n",
    "   Think of OpenClaw like the Linux OS. \n",
    "\n",
    "   If you want to write a custom driver to make a new piece of hardware work, \n",
    "   you don't open the core Linux Kernel source code and hardcode your logic into\n",
    "   the central memory manager. If you did, the very next time Linux released a\n",
    "   security update, your code would be wiped out, or your computer would \n",
    "   instantly crash due to a Git merge conflict. Instead, Linux uses \"Kernel\n",
    "   Modules\" (plugins).\n",
    "\n",
    "   OpenClaw is doing the exact same thing. The core of OpenClaw is an insanely\n",
    "   complex engine handling WebSocket multiplexing, Ed25519 cryptography, mDNS\n",
    "   network discovery, and background daemon lifecycles. YOU DO NOT WANT TO OWN\\\n",
    "   THE TECHNICAL DEBT OF MAINTAINING THAT.\n",
    "\n",
    "   By using the Plugin SDK, you are essentially saying: \"I am going to let the\n",
    "   OpenClaw maintainers deal with the boring networking plumbing, so I can spend\n",
    "   100% of my brainpower on the incredibly difficult task of making an AI\n",
    "   autonomously engineer an Android app.\"\n",
    "\n",
    "   The Plugin SDK doesn't limit your power--it dynamically injects your tools\n",
    "   directly into OpenClaw's root memory space at boot. You still have absolute\n",
    "   control over your computer; you are just practising clean, modular \n",
    "   architecture.\n",
    "\n",
    "\n",
    "   ---\n",
    "   2. THE OpenAI Dilemma: Are model weights really fixed?\n",
    "\n",
    "      Your rant about OAI... frustrating, gaslight-y realities of AI engineering\n",
    "      right now. ... \"If I use a specific, dated model API, is it permanetnly\n",
    "      fixed across all time, or they can change it?\"\n",
    "\n",
    "      ... factual truth about how OAI (and Anthropic) handle this:\n",
    "\n",
    "      \n",
    "      ChatGPT (The Web App) vs. The API\n",
    "\n",
    "      You are 100% right that the ChatGPT web interface is a highly volatile\n",
    "      fluid. OpenAI constantly updates the hidden system prompts, tweaks the RAG\n",
    "      pipelines, and alters guardrails based on PR crises or server load. It is\n",
    "      terrible for reliable production software.\n",
    "   \n",
    "   The API (Pinned models like `gpt-4o-2024-08-06`)\n",
    "      ... THE UNDERLYING WEIGHTS ARE OFFICIALLY DEAD-FIXED. OAI literally\n",
    "      freezes... If you feed it the exact same math problem with the exact same\n",
    "      temperature today and three months from now, the base mathematical \n",
    "      probabilities do not change.\n",
    "\n",
    "   The \"Gotchas\" (Why it still feels fickle)\n",
    "   ...\n",
    "      1. THE INVISIBLE MODERATION LAYER: ... The models didnt change, but the\n",
    "         invisible guardrails surrounding it did.\n",
    "      2. INFERENCE INFRASTRUCTURE TWEAKS: Serving millions of API calls is\n",
    "         astronomically expensive. Cloud providers frequently tweak the hardware\n",
    "         and software running the models (e.g., CUDA kernels, quantization, GPU\n",
    "         batching sizes). These backend infrastructure changing s alter the FP\n",
    "         math just enough that the model's outputs can subtly shift, breaking\n",
    "         strict JSON parsing in your app.\n",
    "      3. FORCED DEPRECATION: They are not fixed across all time. OpenAI\n",
    "         ...  When you migrate to new and different models, your highly-tuned\n",
    "         prompts might break entirely.\n",
    "\n",
    "\n",
    "3. WHY OpenClaw is the ULTIMATE CURE FOR THIS TRAUMA\n",
    "   This exact fear of losing control is why OpenClaw was built, and why you were\n",
    "   ... right to avoid closed-ecoystem frameworks like OAI's official \"Agent SDK\"\n",
    "   or \"Assistants API.\"\n",
    "\n",
    "   If you used OAI's Agent SDK, your agent's core logic, its tools, its memory,\n",
    "   and its orchestration loop would be locked inside OAI's servers. If they\n",
    "   changed their safety filters or deprecated a model, your entire autonomous\n",
    "   Android project would die overnight, and you would be helpless.\n",
    "\n",
    "   By building your own scaffolding inside an OpenClaw Plugin, you maintain\n",
    "   total sovereignty:\n",
    "      - Your ADB terminal commands live safely on your local hard drive.\n",
    "      - Your auto-correction loop runs on your local machine.\n",
    "      - THE LLM IS REDUCED TO A SWAPPABLE \"BRAIN MODULE.\"\n",
    "\n",
    "   Right now, you are using Opus 4.6 via api. If censor... architecture doesn't\n",
    "   care... just open config file and change provider..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb2a547",
   "metadata": {},
   "source": [
    "... looking for the literal, physical step-by-step of where these files live on\n",
    "your hard drive and how the Gateway knows to execute them.\n",
    "\n",
    "You are 100% right: you do NOT type code into CLI line-by-line. ... intuition of\n",
    "using a \"perfectly formatted JSON file detailing all config needed\" is actually\n",
    "exactly how the system works under the hood!\n",
    "\n",
    "Here is the exact missing link: the physical folder structure you will create on\n",
    "your computer, what goes inside the files, and how you hook it up to OpenClaw.\n",
    "\n",
    "\n",
    "1. THE PHYSICAL FOLDER (Where you write the code)\n",
    "   Because you want to stay in stealth..., you don't need to touch OpenClaw's\n",
    "   core code... Anywhere on your computer, (let's say \n",
    "   `~/Documents/stealth-android-plugin/`), you create a standard, private \n",
    "   project folder. You open this folder in your IDE.\n",
    "\n",
    "   It will contain exactly two files:\n",
    "```Plaintext\n",
    "stealth-android-plugin/\n",
    "├── openclaw.plugin.json    <-- The JSON template you guessed would exist\n",
    "└── index.ts                <-- THE ENTRY POINT (where your actual code lives)\n",
    "```\n",
    "   \n",
    "\n",
    "2. WHAT GOES INSIDE THE FILES?\n",
    "   \n",
    "   FILE 1: THE MANIFEST (`openclaw.plugin.json`)\n",
    "      You were completely right about using a JSON file. This file acts as the \n",
    "      ID badge. It tells OpenClaw that this folder is a plugin, what it's called\n",
    "      , and most importantly, WHICH FILE HOLDS YOUR CODE.\n",
    "```JSON\n",
    "{\n",
    "    \"id\": \"opus-android-engineer\",\n",
    "    \"name\": \"Opus Autonomous Builder\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"main\": \"index.ts\",             // This tells OpenClaw where your entry point is!\n",
    "    \"description\": \"Zero-human-in-the-loop Android QA loop\"\n",
    "}\n",
    "```\n",
    "\n",
    "   FILE 2: The Entry Point (`index.ts`)\n",
    "      This is where you actually type your TS/JS code. When OpenClaw reads the\n",
    "      JSON file above, it sees `\"main\": \"index.ts\"`. It then automatically loads\n",
    "      this file into memory and triggers the `register()` function you read \n",
    "      about in the docs.\n",
    "\n",
    "      This is where you write your specific tools:\n",
    "```TS\n",
    "// index.ts\n",
    "\n",
    "// THIS is the exact entry point OpenClaw calls automatically at boot\n",
    "export function register(api) {\n",
    "\n",
    "    console.log(\"Stealth Android Agent is booting up...\");\n",
    "\n",
    "    // 1. You hardcode your custom Gradle tool here\n",
    "    api.registerTool({\n",
    "        name: \"run_gradle_build\",\n",
    "        descrption: \"Compiles the Android app and returns any compiler errors.\",\n",
    "        execute: async (args) => {\n",
    "            // Your actual Node.js logic to run the bash command goes here\n",
    "            const { execSync } = require('child_process');\n",
    "            return execSync('./gradlew assembleDebug').toString()\n",
    "        }\n",
    "    });\n",
    "\n",
    "    // 2. You hardcode your custom ADB tool here\n",
    "    api.registerTool({\n",
    "        name: \"adb_screenshot\",\n",
    "        description: \"Takes a screenshot of the emulator for UI evaluation.\"\n",
    "        execute: async () => {\n",
    "            // ADB execution logic here...\n",
    "        }\n",
    "    });\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0bf68e",
   "metadata": {},
   "source": [
    "3. THE HOOK UP: How does OpenClaw find this folder?\n",
    "   Now that your stealth plugin is written and saved on your hard drive, how\n",
    "   do you get OpenClaw to load it?\n",
    "\n",
    "   If you look at \"Phase 1\" in the documentation you pasted, it says:\n",
    "      > Phase 1 -- Discovery: Scan bundled, global, workspace, and configured\n",
    "      > directories for `openclaw.plugin.json`\n",
    "\n",
    "   This means you just need to tell OpenClaw where your folder is. You have two\n",
    "   standard ways to do this:   \n",
    "\n",
    "   ---\n",
    "\n",
    "   METHOD A: The \"Configured Directory\" (Your hardcdoed JSON config approach)\n",
    "      Wherever you installed OpenClaw, there is a master configuration file for\n",
    "      the Gateway itself (usually `openclaw.config.json` or `workspace.yaml`).\n",
    "      You simply opn that file and hardcode the path to your new stealth folder:\n",
    "\n",
    "```JSON\n",
    "{\n",
    "    \"gatewayPort\": 18789,\n",
    "    \"defaultModel\": \"opus-4.6\",\n",
    "    \"pluginDirectories\": [\n",
    "        \"/Users/.../Documents/stealth-android-plugin\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "   Now, whenever you start the OpenClaw Gateway normally from your terminal \n",
    "   (`openclaw start`), it reads this master config, goes straight to your\n",
    "   Documents folder, reads your `openclaw.plugin.json`, finds `index.ts`, and\n",
    "   permanently injects your custom tools into Opus 4.6's brain.\n",
    "\n",
    "\n",
    "METHOD B: THE \"WORKSPACE\" DIRECTORY (Drop-in)\n",
    "   OpenClaw usually creates a default `plugins/` folder in its root directory.\n",
    "   You can literally just drag-and-drop your entire `stealth-android-plugin`\n",
    "   folder inside it. The next time OpenClaw boots, it automatically scans that\n",
    "   folder, discovers your JSON manifest, and boots your code automatically\n",
    "   without you editing any master configs.\n",
    "\n",
    "\n",
    "---\n",
    "SUMMARY\n",
    "   This is the missing link!\n",
    "   1. You write your logic in a normal code editor inside `index.ts`.\n",
    "   2. You wrap it with the templat `openclaw.plugin.json` file.\n",
    "   3. You tell OpenClaw's master config file where your folder is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed87fd1c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "                                                              o\n",
    "                                                            o%\n",
    "                                                           //\n",
    "                                                      -=\"~\\\n",
    "                                                        ~\\\\\\\n",
    "                                                          \\\\\\\n",
    "                                                           \\\\\\\n",
    "                                                            );\\\n",
    "                                                           /|;;\\\n",
    "                                                      \"\"\";;;;;;;\\\n",
    "                                                ///\"\"\"\"\"\"\"\";;;;;;\\\n",
    "                                    ___////+++++\"\"\"\"\"\"\"\"\"\"\"\"\";;;@@\\\n",
    "                      __________///////++++++++++++++\"\"\"\"\"\"\"\"@@@@%)\n",
    "           ....__/0)///0)//0)//0)/++////////++++++++++\"\"\"@@@%%%%%/\n",
    "     ..---0)/--------////////////////+++++++/////+++++@@%%%%%%%/\n",
    "      ..///---0)---0)///0)//0)///0)/////////+++++====@%%%%%%/\n",
    "   ...0)....//----///------////////////+++++///\"     \\/\\\\//\n",
    "      //../0)--0)///0)///0)///0)//++++/////          /  \\/\n",
    "      --///--------///////////+++/////             _/   /\n",
    ".-//..0).-/0)--0)--0)--0)--..                      /\\  /\n",
    "       .......--/////////.                            /\\_\n",
    "            .0)..0).."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7198319c",
   "metadata": {},
   "source": [
    "4. PLUGIN HOOKS: THE \"INTERCEPTION\" SYSTEM\n",
    "   HOOKS are arguably the most powerful feature in OpenClaw. They act like an\n",
    "   assembly-line checkpoint, allowing your plugin to intercept, pause, modify\n",
    "   , or block the AI's thoughts and actions in real-time.\n",
    "\n",
    "   - `before_agent_start`: Right before the AI generates a response or writes\n",
    "     code, this hook pauses the process. You can use this to silently inject\n",
    "     live data into the AI's hidden system prompt (e.g., \"System update:\n",
    "     The Android emulator currently has 15% CPU usage and the last Gradle build\n",
    "     failed.\")\n",
    "   - `before_tool_call` (Your Ultimate Safety Net): Because you are giving an AI\n",
    "     access to a live terminal, safety is paramount. If Opus hallcuinates to run\n",
    "     a destructive command like `rm -rf /` (deleting your hard drive), this hook\n",
    "     catches it mid-air. Your code can inspect the bash command, realise it's \n",
    "     dangerous, block the execution entirely, and return a scolded error message\n",
    "     to the AI.\n",
    "   - `after_tool_call` (THE SELF-HEALING LOOP): If Opus runs your \n",
    "     `run_gradle_build` tool and it fails, you can use this hook to instantly\n",
    "     parse the massive Java stack trace, extract the line of code that broke, \n",
    "     and forcefully inject it into the AI's next prompt so it can self-correct\n",
    "     immediately without you having to copy-paste tje error.\n",
    "\n",
    "\n",
    "5. CHANNEL PLUGINS: THE \"EARS AND MOUTH\"\n",
    "   The last section of your snippet defines a highly-complex, specialised type\n",
    "   of plugin:\n",
    "      the CHANNEL PLUGIN.\n",
    "\n",
    "   This is specifically designed to connect OpenClaw to external chat platforms\n",
    "   like Discord, Telegram, Slack or WhatsApp.\n",
    "\n",
    "   Because every chat app works differently, a Channel Plugin normalises the \n",
    "   Chaos:\n",
    "   - `auth`/`security`: Handles the messy OAuth logins or Bot Tokens so OpenClaw\n",
    "     can authenticate as a real bot on on Discord.\n",
    "   - `messaging`: Translates OpenClaw's internal text into Discord's specific\n",
    "     JSON format so code blocks and bold text render beautifully.\n",
    "   - `agentTools` (Context-Aware Tools): This is brilliant. A Channel Plugin\n",
    "     can grant Opus tools that only exist in that specific chat app. If Opus\n",
    "     is talking to you in a Discord channel, it might get a \n",
    "     `create_voice_channel` tool. If Opus is talking to you via standard SMS,\n",
    "     that tool disappears from its brain because SMS doesn't support voice\n",
    "      channels.\n",
    "\n",
    "\n",
    "SUMMARY: Your Action Plan\n",
    "   To achieve your dream of a zero-human-in-the-loop Android Developer, you do\n",
    "   not need a Channel Plugin. You just need a standard plugin.\n",
    "\n",
    "   You will create a folder called `opus-android-engineer-plugin`.\n",
    "   1. You will write an `openclaw.plugin.json` asking for the SDK path.\n",
    "   2. In your `register()` function, you will use `registerTool()` to give Opus\n",
    "      your custom Bash, ADB, and Vision tools.\n",
    "   3. You will use `registerService()` to manage the headless emulator.\n",
    "   4. You will use the `before_tool_call` hook to ensure Opus only runs safe\n",
    "      Gradle commands.\n",
    "\n",
    "   This architecture keeps the core system secure and infinitely modular while\n",
    "   giving your AI the exact, isolated superpowers it needs to build apps \n",
    "   entirely on its own!      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa0e03",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "                                                              o\n",
    "                                                            o%\n",
    "                                                           //\n",
    "                                                      -=\"~\\\n",
    "                                                        ~\\\\\\\n",
    "                                                          \\\\\\\n",
    "                                                           \\\\\\\n",
    "                                                            );\\\n",
    "                                                           /|;;\\\n",
    "                                                      \"\"\";;;;;;;\\\n",
    "                                                ///\"\"\"\"\"\"\"\";;;;;;\\\n",
    "                                    ___////+++++\"\"\"\"\"\"\"\"\"\"\"\"\";;;@@\\\n",
    "                      __________///////++++++++++++++\"\"\"\"\"\"\"\"@@@@%)\n",
    "           ....__/0)///0)//0)//0)/++////////++++++++++\"\"\"@@@%%%%%/\n",
    "     ..---0)/--------////////////////+++++++/////+++++@@%%%%%%%/\n",
    "      ..///---0)---0)///0)//0)///0)/////////+++++====@%%%%%%/\n",
    "   ...0)....//----///------////////////+++++///\"     \\/\\\\//\n",
    "      //../0)--0)///0)///0)///0)//++++/////          /  \\/\n",
    "      --///--------///////////+++/////             _/   /\n",
    ".-//..0).-/0)--0)--0)--0)--..                      /\\  /\n",
    "       .......--/////////.                            /\\_\n",
    "            .0)..0).."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943b5527",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "That covers the four major systems. The most critical part for your autonomous\n",
    "Android app deployment goal are:\n",
    "\n",
    "   1. THE EXEC TOOL (`bash-tools.exec.ts`) - this is how you'll run \n",
    "      `./gradlew assembleDebug`\n",
    "   2. BACKGROUND PROCESS MANAGEMENT (`bash-tools.process.ts`) - Android builds \n",
    "      are slow, need background execution\n",
    "   3. THE SUBAGENT SYSTEM (`sessions-spawn-tool.ts`) - for parallelising build\n",
    "      steps\n",
    "   4. THE SKILL SYSTEM - for packaging your android-app-builder workflow as a\n",
    "      reusable skill\n",
    "   5. THE PLUGIN SDK - for adding custom deployment tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ff412",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "                Dusk\n",
    "              above the\n",
    "          water hang the\n",
    "                    loud\n",
    "                   flies\n",
    "                   Here\n",
    "                  O so\n",
    "                 gray\n",
    "                then\n",
    "               what            A pale signal will appear\n",
    "              when        Soon before its shadow fades\n",
    "             where      Here in this pool of opened eye\n",
    "            in us     No upon us As at the very edges\n",
    "             of where we take shape in the dark air\n",
    "              This object bares its image awakening\n",
    "                ripples of recognition that will\n",
    "                   brush darkness up into light\n",
    "even after this bird this hour both drift byatop the perfect\n",
    "sad instant now     already passing out of sight\n",
    "                 toward yet-untroubled reflection\n",
    "               this image bares its object darkening\n",
    "              into memorial shades scattered bits of\n",
    "            light      No of water Or something across\n",
    "            water        Breaking up no being regathered\n",
    "             soon          Yet by then a swan will have\n",
    "              gone              yes out of mind into what\n",
    "               vast\n",
    "                pale\n",
    "                 hush\n",
    "                  of a\n",
    "                  place\n",
    "                   past\n",
    "         sudden dark as\n",
    "             if a swan\n",
    "                sang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77c1bc",
   "metadata": {},
   "source": [
    "Both explorations are done. Here's everything compiled, focused on your question\n",
    ": WHAT SCAFFOLDING EXISTS FOR CHECKING THAT THINGS WORK, AND WHAT YOU'D NEED TO\n",
    "BUILD.\n",
    "\n",
    "---\n",
    "THE ERROR FEEDBACK LOOP (Already built into OpenClaw)\n",
    "   This is the core mechanism that makes self-correction possible. It already \n",
    "   works end-to-end.\n",
    "\n",
    "HOW IT WORKS\n",
    "   1. Agent calls exec: `./gradlew assembleDebug`\n",
    "   -->\n",
    "   2. Command runs. stdout + stderr captured CONTINUOUSLY\n",
    "      (`bash-tools.exec.ts:678-684`)\n",
    "   -->   \n",
    "   3. Exit code checked (line 714):\n",
    "      `const isSuccess = code === 00 && !wasSignal && !timedOut;`\n",
    "   -->\n",
    "   4. If FAILED, error formatted (lines 727-734):\n",
    "      - Timeout:  \"Command timed out after X seconds\"\n",
    "      - Signal:   \"Command aborted by signal SIGKILL\"\n",
    "      - Non-zero: \"Command exoited with code 1\"\n",
    "      - Full stdout+stderr PREPENDED above the exit reason\n",
    "   -->\n",
    "   5. Tool result returned to LLM (L 1604):\n",
    "      text: `\"${fullOutput}\\n\\nCommand exited with code 1\"`\n",
    "      details: `{ status: \"failed\", exitCode: 1, durationMs: ... }`\n",
    "   -->\n",
    "   6. Model SEES all of this in its next turn.\n",
    "      It an read the Gradle stactrace, fix the code, re-run.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "WHAT THE MODEL SEES AFTER A FAILED BUILD\n",
    "   Concretely, if `./gradlew assembleDebug` fails, the model gets back something\n",
    "   like:\n",
    "\n",
    "   ```bash\n",
    "   > Task :app:compileDebugKotlin FAILED\n",
    "   e: file:///app/src/main/java/com/example/MainActivity.kt:15:%\n",
    "     Unresolved reference: setContents\n",
    "\n",
    "   BUILD FAILED in 34s\n",
    "   3 actionable tasks: 1 executed, 2 up-to-date\n",
    "\n",
    "   Command exited with code 1  \n",
    "   ```\n",
    "\n",
    "   The model sees the FULL ERROR, knows the FILE AND LINE NUMBER, and has the \n",
    "   `edit` and `exec` tools to fix it and retry. This loop is identical to how \n",
    "   Claude Code works.\n",
    "\n",
    "\n",
    "\n",
    "TRUNCATION FOR HUGE OUTPUTS\n",
    "   From `tool-result-truncation.ts`:\n",
    "   - Max tool result = `30% of context window`  (line 60)\n",
    "   - Hard cap: `400,000 chars`                  (line 19)\n",
    "   - Minimum kept: `2,000 chars` from the start (line 26)\n",
    "   - If truncated, a warning is appended: \n",
    "         `\"[Content truncated -- original was too large]\"`\n",
    "   - For a 128K token model: ~26K char limit\n",
    "   - For a 2M token model: capped at 400K chars.\n",
    "\n",
    "   So even massive Gradle outputs get handled gracefully.      \n",
    "\n",
    "\n",
    "---\n",
    "IS OPENCLAW A CODING AGENT? (Yes, but implicitly)\n",
    "   \n",
    "   WHAT ALREADY EXISTS\n",
    "      OpenClaw bundles `pi-coding-agent` (imported as `pi-tools.ts:1-7`) which\n",
    "      provides:\n",
    "      - `exec` - Run any shell command (builds, tests, linters)\n",
    "      - `process` - Background processes with PTY support\n",
    "      - `read` / `write` / `edit` - File operations\n",
    "      - `apply-patch` - Git patch application\n",
    "\n",
    "      These are the SAME PRIMITIVES that Claude Code uses. The self-correction\n",
    "      behaviour you described (\"Claude sometimes writes unit tests by itself,\n",
    "      runs `python3` to check things\") comes from the MODEL'S OWN INTELLIGENCE,\n",
    "      NOT FROM hardcoded logic.#\n",
    "\n",
    "\n",
    "   WHAT DOES NOT EXIST (You'd Need to Build)\n",
    "   From `system-prompt.ts` -- there are NO EXPLICIT INSTRUCTIONS telling the \n",
    "   model to:\n",
    "      - Automatically run tests after writing code\n",
    "      - Verify compilation before moving on\n",
    "      - Check linting\n",
    "      - Auto-retry on failure\n",
    "\n",
    "   The model CAN do all of these (it has the tools), but it's not TOLD to. In\n",
    "   Claude Code, this behavior comes from Anthropic's specific system prompt\n",
    "   tuning. In OpenClaw, you'd add it yourself.\n",
    "\n",
    "   THIS IS YOUR SCAFFOLDING GAP. You need to add instructions to the system\n",
    "   prompt or build wrapper tools.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "BROWSER && UI TESTING CAPABILITIES (Already Built)\n",
    "   This is where OpenClaw is actually VERY STRONG and directly relevant to your\n",
    "   \"check the app doesn't crash / broken navigation\" requirement.\n",
    "\n",
    "   \n",
    "   THE BROWSER TOOL (Playwright-Powered)\n",
    "      `src/agents/tools/browser-tool.ts` - Full Playwright integration via CDP:\n",
    "\n",
    "   INTERACTION ACTIONS (schema lines 4-15):\n",
    "\n",
    "   // Action // What it does //\n",
    "   `click` // Click element (supports double-click, modifiers)\n",
    "   `type` // Type text (with slow mode, submit option)\n",
    "   `press` // Press keyboard key\n",
    "   `hover` // Hover over element\n",
    "   `drag` // Drag from element to element\n",
    "   `select` // Select dropdown option\n",
    "   `fill` // Fill form fields\n",
    "   `resize` // Resize window\n",
    "   `wait` // Wait for condition (text, selector, URL, load state)\n",
    "   `evaluate` // Run arbitrary JavaScript\n",
    "   `close` // Close tab/window\n",
    "\n",
    "\n",
    "SNAPSHOT && VERIFICATION:\n",
    "   - `snapshot` - AI-readable DOM structure with element refs like `e1`, `e2`\n",
    "   - `screenshot` - Full page or specific element, PNG/JPEG, max 2000px\n",
    "   - `console` - Retrieve console messages (catch JS errors!)\n",
    "   - `pdf` - Export page to PDF\n",
    "\n",
    "ELEMENT LOCATION FLOW:\n",
    "   1. Agent takes a `snapshot` --> gets DOM tree with refs\n",
    "   2. Agent clicks `ref: e1` (the submit button)\n",
    "   3. Agent takes another `snapshot` --> check if page changed\n",
    "   4. Agent takes `screenshot` --> analysis with vision model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa46467b",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "(\\o/)___________________________________________________________(\\o/)\n",
    "(/|\\)                                                           (/|\\)\n",
    "  |                                          .-~~~-.              |\n",
    "  |                                        /        }             |\n",
    "  |                                       /      .-~              |\n",
    "  |                             \\        |        }               |\n",
    "  |             __   __       ___\\.~~-.-~|     . -~_              |\n",
    "  |            / \\./  \\/\\_       { O |  ` .-~.    ;  ~-.__        |\n",
    "  |        __{^\\_ _}_   )  }/^\\   ~--~/-|_\\|   :   : .-~          |\n",
    "  |       /  /\\_/^\\._}_/  //  /     /   |  \\~ - - ~               |\n",
    "  |      (  (__{(@)}\\__}.//_/__A__/_A___|__A_\\___A______A_____A   |\n",
    "  |       \\__/{/(_)\\_}  )\\\\ \\\\---v-----V----v----v-----V-----v--- |\n",
    "  |         (   (__)_)_/  )\\ \\>                                   |\n",
    "  |          \\__/     \\__/\\/\\/                                    |\n",
    "  |             \\__,--'                                           |\n",
    "  |                                                               |\n",
    "(\\o/)___________________________________________________________(\\o/)\n",
    "(/|\\)                                                           (/|\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832c028a",
   "metadata": {},
   "source": [
    "THE IMAGE ANALYSIS TOOL (Vision AI)\n",
    "\n",
    "   `src/agents/tools/image-tool.ts` - Send screenshots to vision models for\n",
    "   analysis:\n",
    "   - MODELS: Claude Opus 4.6 (primary), MiniMax-VL-01, GPT-5-mini\n",
    "   - USE CASE: Take screenshot --> ask \"is this UI broken? Are there overlapping\n",
    "     elements? Is the back button visible?\" \n",
    "\n",
    "   This is your VISUAL REGRESSION TESTING - the agent can literally LOOK at the\n",
    "   app and judge if something's wrong.\n",
    "\n",
    "\n",
    "\n",
    "THE NODES TOOL (Android Device Control)\n",
    "   `src/agents/tools/nodes-tool.ts` - Direct Android device interaction:\n",
    "\n",
    "   // Action // What It Does //\n",
    "    `camera_snap` // Take photo from front/back camera\n",
    "    `screen_record` // Record device screen (MP4, configurable duration/FPS)\n",
    "    `location_get` // Get device GPS location\n",
    "    `notify` // Send system notification\n",
    "    `run` // Execute shell commands ON the device\n",
    "    `invoke` // Call arbitrary node commands\n",
    "\n",
    "   FOR ANDROID APP TESTING:\n",
    "   - Install APK via `run` (adb install)\n",
    "   - Launch app via `run` (adb shell am start)\n",
    "   - Record screend during test via `screen_record`\n",
    "   - Take screenshot via `camera_snap`\n",
    "   - Analyse screenshot with vision model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6295af2",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "(\\o/)___________________________________________________________(\\o/)\n",
    "(/|\\)                                                           (/|\\)\n",
    "  |                                          .-~~~-.              |\n",
    "  |                                        /        }             |\n",
    "  |                                       /      .-~              |\n",
    "  |                             \\        |        }               |\n",
    "  |             __   __       ___\\.~~-.-~|     . -~_              |\n",
    "  |            / \\./  \\/\\_       { O |  ` .-~.    ;  ~-.__        |\n",
    "  |        __{^\\_ _}_   )  }/^\\   ~--~/-|_\\|   :   : .-~          |\n",
    "  |       /  /\\_/^\\._}_/  //  /     /   |  \\~ - - ~               |\n",
    "  |      (  (__{(@)}\\__}.//_/__A__/_A___|__A_\\___A______A_____A   |\n",
    "  |       \\__/{/(_)\\_}  )\\\\ \\\\---v-----V----v----v-----V-----v--- |\n",
    "  |         (   (__)_)_/  )\\ \\>                                   |\n",
    "  |          \\__/     \\__/\\/\\/                                    |\n",
    "  |             \\__,--'                                           |\n",
    "  |                                                               |\n",
    "(\\o/)___________________________________________________________(\\o/)\n",
    "(/|\\)                                                           (/|\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e7f8e",
   "metadata": {},
   "source": [
    "WHAT SCAFFOLDING YOU NEED TO BUILD\n",
    "   Here's the concrete gap analysis--what exists vs. what you need for \n",
    "   end-to-end autonomous Android app development:\n",
    "\n",
    "---\n",
    "LAYER 1: COMPILATION CHECK (Easy - System Prompt Addition)\n",
    "\n",
    "   EXISTS: `exec` tool, error feedback loop, full stderr capture\n",
    "   MISSING: Instructions telling the model to verify compilation\n",
    "\n",
    "   SOLUTION: Add to system prompt or create a skill:\n",
    "      After writing or modifying any Android source file, ALWAYS run:\n",
    "        `> ./gradlew assembleDebug`\n",
    "      If it fails, readd the error output, fix the code, and re-run until it\n",
    "      compiles successfully. Do NOT move on until the build passes.\n",
    "\n",
    "\n",
    "LAYER 2: UNIT TEST EXECUTION (Easy - System Prompt Addition)\n",
    "   \n",
    "   EXISTS: `exec` tool can run `./gradlew testDebugUnitTest`\n",
    "   MISSING: Instructions to write and run tests\n",
    "\n",
    "   SOLUTION: Add to system prompt:\n",
    "      After implementing any feature, write unit tests and run:\n",
    "         `./gradlew testDebugUnitTest`\n",
    "      Fix any failures before proceeding.\n",
    "\n",
    "\n",
    "LAYER 3: APK PACKAGING VERIFICATION (EASY - Exec Check)\n",
    "   \n",
    "   EXISTS: `exec` tool, file `read` tool\n",
    "   MISSING: Nothing - agent can already check APK exists\n",
    "\n",
    "   SOLUTION: System prompt instruction:\n",
    "      After `assembleDebug`, verify the APK exists at:\n",
    "         `app/build/outputs/apk/debu/*/apk`\n",
    "      Read the file size to confirm it's a valid APK (should be > 1 MB).\n",
    "\n",
    "\n",
    "LAYER 4: UI TESTING ON EMULATOR (MEDIUM - Needs Setup)\n",
    "   \n",
    "   EXISTS: `exec` (can run ADB), `process` (for long-running emulator), browser\n",
    "      tool (for web-based testing)\n",
    "   MISSING: Android emulator setup in sandbox, ADB integration\n",
    "\n",
    "   WHAT YOU'D BUILD:\n",
    "      1. Docker image with Android SDK + emulator (or connect to physical\n",
    "         device)\n",
    "      2. System Prompt instructions:\n",
    "\n",
    "```Bash\n",
    "1. Install on emulator: `adb install -r app.apk`\n",
    "2. Launch app: `adb shell am start -n com.example/.MainActivity`\n",
    "3. Wait 5 seconds for app to load\n",
    "4. Take screnshot: `adb exec-out screencap -p > screenshot.png`\n",
    "5. Analyse screenshot with image tool - check for crashes, blank screens\n",
    "6. Test navigation: use `adb shell input tap X Y` to tap buttons\n",
    "7. After each tap, screenshot again and verify no crash\n",
    "```\n",
    "\n",
    "\n",
    "LAYER 5: NAVIGATION & CRASH DETECTION (MEDIUM - Vision + ADB)\n",
    "   \n",
    "   EXISTS: Image tool (vision analysis), nodes tool (`screen_record`), exec tool\n",
    "      (`ADB`).\n",
    "   MISSING: Structured test flow\n",
    "\n",
    "   WHAT YOU'D BUILD -- a custom \"android-ui-test\" skill:\n",
    "      For each screen in the app:\n",
    "         1. Screenshot the current screen\n",
    "         2. Analyse: \"List all clickable elements and their positions\"\n",
    "         3. For each button/link:\n",
    "            a. Tap it (`adb shell input tap X Y`)\n",
    "            b. Wait 2 seconds\n",
    "            c. Screenshot\n",
    "            d. Analyse: \"Did the app crash? Is there a back button? Can the \n",
    "               user return to the previous screen?\"\n",
    "            e. If no back button: FLAG as navigation issue\n",
    "            f. Press back: `adb shell input keyevent KEYCODE_BACK`\n",
    "            g. Screenshot again: verify we're back to original screen\n",
    "         4. Check logcat for crashes: `adb logcat -d *:E | grep FATAL`               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695cd2f9",
   "metadata": {},
   "source": [
    "LAYER 6: LOGCAT CRASH DETECTION (EASY - Exec)\n",
    "   \n",
    "   EXISTS: `exec` tool\n",
    "   MISSING: Nothing\n",
    "\n",
    "   SOLUTION: After any test action:\n",
    "      `adb logcat -d *:E | grep -E \"(FATAL|AND|crash|Exception)\"`\n",
    "\n",
    "   If output is non-empty --> app crashed --> model reads the stacktrace -->\n",
    "   fixes code.\n",
    "\n",
    "\n",
    "LAYER 7: End-to-End Pipeline Orchestration (HARD - Custom Plugin/Skill)\n",
    "\n",
    "   EXISTS: Subagent spawning, skills system, plugin SDK\n",
    "   MISSING: The orchestration layer tying it all together\n",
    "\n",
    "   WHAT YOU'D BUILD - \"android-deploy\" plugin or skill:\n",
    "   Phase 1: Generate (subagent)\n",
    "      - Write Kotlin code\n",
    "      - Write build.gradle\n",
    "      - Write AndroidManifest.xml\n",
    "\n",
    "   Phase 2: Build (exec)\n",
    "      - `./gradlew assembleDebug`\n",
    "      - If fail -> fix -> retry (up to 5 times)\n",
    "\n",
    "   Phase 3: Test (exec + image + nodes)\n",
    "      - Install on emulator/device\n",
    "      - Run UI smoke tests\n",
    "      - Check logcat for crashes\n",
    "      - Vision-check screenshots\n",
    "\n",
    "   Phase 4: Package (exec)\n",
    "      - Sign APK (if release)\n",
    "      - Verify APK integrity\n",
    "\n",
    "   Phase 5: Deploy (exec)\n",
    "      - `adb install for local`\n",
    "      - (Future: Play Store upload via API)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "SUMMARY: WHAT'S FREE vs. WHAT YOU BUILD\n",
    "   \n",
    "   // Capability // Status // How\n",
    "   Run build commands // FREE // `exec` tool already exists\n",
    "   See compilation errors // FREE // stderr captured, sent to model\n",
    "   Model self-corrects on error // FREE // Feedback loop built-in\n",
    "   Model runs tests // FREE (needs prompt) // Add system prompt instruction\n",
    "   Truncate huge outputs // FREE // Auto-truncation with warning\n",
    "   Background long builds // FREE // `process` tool with `yieldMs`\n",
    "   Browser UI testing // FREE // Playwright via browser tool\n",
    "   Screenshot analysis // FREE // Vision model via image tool\n",
    "   Android screen recording // FREE // `screen_record` via nodes tool\n",
    "   ADB commands // FREE (needs prompt) // Via `exec` tool\n",
    "   Logcat crash detection // FREE (needs prompt) // Via `exec` + grep\n",
    "\n",
    "   Navigation testing // BUILD // Custom skill with ADB + vision\n",
    "   Emulator in sandbox // BUILD // Custom Docker image\n",
    "   End-to-end pipeline // BUILD // Custom skill or plugin\n",
    "   Auto-retry on build fail // BUILD // System prompt or wrapper tool.\n",
    "\n",
    "\n",
    "The short answer to your quesstion: OpenClaw already has 80% of what you need.\n",
    "The error feedback loop, tool execution, file editing, browser testing, vision\n",
    "analysis -- all built in. What's missing is the ANDROID-SPECIFIC ORCHESTRATION\n",
    "LAYER (system prompt instructions + a custom skill that ties the pieces together\n",
    "into a structured workflow).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c82047",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "(\\o/)___________________________________________________________(\\o/)\n",
    "(/|\\)                                                           (/|\\)\n",
    "  |                                          .-~~~-.              |\n",
    "  |                                        /        }             |\n",
    "  |                                       /      .-~              |\n",
    "  |                             \\        |        }               |\n",
    "  |             __   __       ___\\.~~-.-~|     . -~_              |\n",
    "  |            / \\./  \\/\\_       { O |  ` .-~.    ;  ~-.__        |\n",
    "  |        __{^\\_ _}_   )  }/^\\   ~--~/-|_\\|   :   : .-~          |\n",
    "  |       /  /\\_/^\\._}_/  //  /     /   |  \\~ - - ~               |\n",
    "  |      (  (__{(@)}\\__}.//_/__A__/_A___|__A_\\___A______A_____A   |\n",
    "  |       \\__/{/(_)\\_}  )\\\\ \\\\---v-----V----v----v-----V-----v--- |\n",
    "  |         (   (__)_)_/  )\\ \\>                                   |\n",
    "  |          \\__/     \\__/\\/\\/                                    |\n",
    "  |             \\__,--'                                           |\n",
    "  |                                                               |\n",
    "(\\o/)___________________________________________________________(\\o/)\n",
    "(/|\\)                                                           (/|\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7522d759",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ef14a3",
   "metadata": {},
   "source": [
    "- DOM: The Document Object Model (DOM) is an application programming interface\n",
    "  (API) in HTML and XML documents. It defines the logical structure of documents\n",
    "  and the way a document is accessed and manipulated.\n",
    "  \n",
    "\n",
    "\n",
    "- Hooks are instructions that can be inserted into a program by a compiler at\n",
    "  compile time. Hooks can be placed at entrances and exits of blocks, at \n",
    "  statement boundaries, and at points in the program where program flow might\n",
    "  change between statemenet boundaries (called path points).\n",
    "\n",
    "- Hooks in agentic AI are specialised, customisable, and event-driven code \n",
    "  snippets that run at specific stages of an AI agent's lifecycle. They act as\n",
    "  interception points, allowing developers to observe, control, modify or extend\n",
    "  agent actions--such as tool usage, planning, or execution steps--without\n",
    "  changing the core model's logic.\n",
    "\n",
    "\n",
    "- ADB: Android Debug Bridge (`adb`) is a versatile command-line tool that lets\n",
    "  you communicate with a device. The adb commands facilitates a variety of \n",
    "  device actions, such as installing and debugging apps. `adb` provides access\n",
    "  to a Unix shell that you can use to run a variety of commands on a device."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

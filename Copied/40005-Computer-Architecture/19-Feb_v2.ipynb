{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb81813",
   "metadata": {},
   "source": [
    "It really is beautiful when the abstract logic connects direclty to the physical\n",
    "silicon. You are starting to see the \"Matrix\" of how software actually runs!\n",
    "\n",
    "These ... how we build instructions to how fast the computer can execute them. \n",
    "\n",
    "\n",
    "---\n",
    "1. THE MEANING OF \"PERFORMANCE\" (P3)\n",
    "   When we talk about performance, we aren't just talking about abstract speed.\n",
    "   It depends on your goal:\n",
    "   - PURCHASING PERSPECTIVE: You want the best performance for your budget.\n",
    "   - DESIGN PERSPECTIVE: As an architect, you want to build a machine that \n",
    "     out-performs competittors while keeping manufacturing costs low.\n",
    "\n",
    "   To do either of these, you need a standard, mathematical way to calculate and\n",
    "   compare performance so you aren't just guessing.\n",
    "\n",
    "\n",
    "---\n",
    "2. THE GOLDEN EQUATION (P4)     \n",
    "   This is the most important formula in computer architecture. Do not just look\n",
    "   at a computer's \"GHz\" (clock speed) to know if it is fast! The true metric is\n",
    "   EXECUTION TIME.\n",
    "\n",
    "   `EXECUTION TIME = Instruction Count \\times CPI \\times Cycle Time`\n",
    "\n",
    "   - INSTRUCTION COUNT: How many lines of assembly code (like the 32-bit R-types\n",
    "     and J-types we just looked at) does it take to run your program?\n",
    "   - CPI (CYCLES PER INSTRUCTION): On average, how many \"ticks\" of the \n",
    "     computer's clock does it take to finish one instruction? (Addition migh\n",
    "     take 1 tick; pulling data from RAM might take 10 ticks).\n",
    "   - CYCLE TIME: The physical length of one clock tick in seconds (e.g., 250 ps)\n",
    "\n",
    "   EXAMPLE: ...\n",
    "\n",
    "\n",
    "---    \n",
    "3. COMPARING TWO PROCESSORS (P5 && P6)\n",
    "   These slides present a math problem: How do you compare two processors (M1\n",
    "   and M2) that have different clock speeds and different CPIs?\n",
    "\n",
    "   WHY IT MATTERS: Your professor stresses that you should compare the ratio of\n",
    "   their execution times, NOT just compare how many instructions they can do per\n",
    "   second.\n",
    "      - EXAMPLE: If M1 finishes a task in 10 seconds, and M2 finishes the \n",
    "        identical task in 5 seconds, M2 is twice as fast. You just plug the \n",
    "        `Count`, `CPI`, and `Clock Speed` into the Golden Equation for both, and\n",
    "        divide them.\n",
    "\n",
    "\n",
    "---\n",
    "4. WHAT AFFECTS THE GOLDEN EQUATION? (P7)\n",
    "   This table is brilliant because it connects software engineering directly to\n",
    "   hardware performance.\n",
    "\n",
    "   - ALGORITHM: Affects Instruction Count and CPI.\n",
    "      - Why Count? An inefficient sorting algorithm will require the CPU to \n",
    "        execute millions of extra instructions.\n",
    "      - Why CPI? If your algorithm relies heavily on division (a slow operation\n",
    "        taking many cycles), your average CPI goes up. If you rewrite it to use\n",
    "        bit-shifts (a fast operation), your CPI drops.\n",
    "   - LANGUAGE: Affects Instruction Count and CPI.\n",
    "      - Why? A low-level language like C compiles down to very few instructions.\n",
    "        A high-level language like Java requires a virtual machine and indirect\n",
    "        calls, meaning more instructions and higher CPI.\n",
    "   - COMPILER: Affects Instruction Count and CPI.\n",
    "      - Why? A \"smart\" compiler might realise your code has a useless loop and\n",
    "        delete it entirely before it even becomes assembly code, slashing the\n",
    "        Instruction Count.\n",
    "   - INSTRUCTION SET (ISA): Affects Count, CPI and Clock Rate.\n",
    "      - Why? If the blueprint (like RISC-V) is simple, you can clock the chip\n",
    "        faster.\n",
    "   - ORGANISATION & TECHNOLOGY: Affects Clock Rate.\n",
    "      - Why? This is purely the electrical engineering side. Using better \n",
    "        silicon manufacturing lets the chip tick faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb7b53",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "5. HISTORICAL CHALLENGES (P8)\n",
    "   This graph tells the story of the last 40 years of computing.\n",
    "      - The CISC Era: Computers had massive, complex instructions. Performance\n",
    "        growth was steady but slow (22% per year).\n",
    "      - The RISC Era: Architects realised that by forcing instructions to be\n",
    "        dead-simple and uniform (like the 32-bit R-types we discussed), they\n",
    "        could drastically lower the CPI. Performance exploded (52% per year).\n",
    "      - The Multicore Era: Eventually, we hit the physical limits of silicon\n",
    "        thermodynamics (End of Dennard Scaling). We couldn't safely push clock\n",
    "        speeds higher without melting the chip, so we just started gluing\n",
    "        multiple processors together (Multicore).\n",
    "        \n",
    "\n",
    "---\n",
    "6. THE REAL-WORLD PROOF: RISC vs CISC (P9)\n",
    "   The slide uses the Golden Equation to prove why RISC beat CISC. It compares\n",
    "   an old SUN 68000 (CISC) to a newer SUN RISC (SPARC).\n",
    "   - The Disadvantages of RISC: The RISC machine required more instructions to \n",
    "     do the same job (Instruction count ratio of 1.25), and its physical clock\n",
    "     was actually slower (60ns vs 40ns cycle time).\n",
    "   - WHY DID IT WIN? Look at the CPI. The CISC machine took 5.0 to 7.0 cycles\n",
    "     per instruction. The RISC machine only took 1.3 to 1.7 cycles!\n",
    "   - THE RESULT: Even though the RISC machine had a worse clock and had to read\n",
    "     more lines of code, because every instruction finishes so rapidly (low CPI)\n",
    "     , it completed the entire program in half the time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790cfb0f",
   "metadata": {},
   "source": [
    "... Going from the physical constraints of an architecture to how we actually\n",
    "measure its success is the perfect progression.\n",
    "\n",
    "\n",
    "---\n",
    "1. THE RISC Secret && The Compromise (P10)\n",
    "   This page formally spells out exactly why the RISC architecture (like the\n",
    "   RISC-V you are studying) took over the computing world.\n",
    "   - THE PRINCIPLE: \"Make the common case fast.\" By making instructions \n",
    "     incredibly simple and uniform (always 32 bits, always doing one small task)\n",
    "     , hardware engineers can optimise the physical silicon to run those basic \n",
    "     tasks lightning-fast. This aggressively reduces the CPI (Cycles Per\n",
    "     Instruction) and allows for a faster clock cycle time.\n",
    "   - THE TRADE-OFF: There is no free lunch in CS. Because each instruction is so\n",
    "     simple, you need more of them to accomplish a complex task.\n",
    "   - EXAMPLE: If a CISC processor has a complex \"Calculate Square Root\" \n",
    "     instruction, it takes 1 line of code but maybe 50 clock cycles to finish. A\n",
    "     RISC processor might require 15 lines of basic math instructions to \n",
    "     calculate that same square root, but each line only takes 1 clock cycle.\n",
    "     RISC wins because 15 total cycles is still much faster than 50.\n",
    "\n",
    "\n",
    "---\n",
    "2. HOW TO KEEP GETTING FASTER (P11)\n",
    "   Since we hit the physical limit of how fast we can make a single processor\n",
    "   \"tick\" (the \"End of Dennard Scaling\" mentioned earlier), computer architects\n",
    "   had to get creative to keep improving performance:\n",
    "\n",
    "   - CACHES (Fast Local Store): Fetching data from main memory (RAM) is\n",
    "     agonisingly slow. Caches act like a small, ultra-fast desk drawer right\n",
    "     inside the CPU so it doesn't have to walk to the filing cabinet (RAM) every\n",
    "     time. \n",
    "   - PIPELINING & SUPERSCALAR (Concurrent Execution): Instead of waiting for one\n",
    "     instruction to finish completely before starting the next, the CPU operates\n",
    "     like an assembly line, overlapping the fetch, decode, and execute steps of\n",
    "     multiple instructions simultaneously.\n",
    "   - DOMAIN-SPECIFIC HARDWARE: This is TPU concept from L1! For specific tasks\n",
    "     like AI or graphics, we use customised silicon (like GPUs or FPGAs) instead\n",
    "     of general-purpose CPUs.\n",
    "\n",
    "\n",
    "---\n",
    "3. EVALUATING PERFORMANCE HONESTLY (P12 && P13)\n",
    "   How do you actually prove your new CPU design is better? You cannot just rely\n",
    "   on clock speed or \"MIPS\" (Million Instruction Per Second).\n",
    "      - WHY MIPS IS FLAWED: If a RISC processor runs 10 million simple \n",
    "        instructions per second, and a CISC processor runs 5 million complex\n",
    "        instructions per second, MIPS makes the RISC look twice as fast. But if\n",
    "        the CISC's complex instructions were doing significantly more work, it\n",
    "        might finish the actual program sooner!\n",
    "      - THE SOLUTION: We use Benchmarks.\n",
    "         - ACTUAL TARGET WORKLOAD: Testing the exact software the user runs.\n",
    "           Extremely accurate, but not portabele to other users.\n",
    "         - FULL APPLICATION BENCHMARKS: A standardised suite of real-world \n",
    "           programs. This is highly representative and widely used.\n",
    "         - SMALL KERNEL BENCHMARKS: Testing tiny, specific loops of code. Great\n",
    "           for early hardware design, but rarely reflects true real-world\n",
    "           performance.\n",
    "\n",
    "\n",
    "---\n",
    "4. The SPEC Benchmark in Action (P14 & 15)\n",
    "   SPEC (System Performance Evaluation Co-operative) is the gold standard for\n",
    "   full-application benchmarking. The CPU2000 version runs 26 different \n",
    "   intensive programs (like compiling C code, chess AI, or video compression) to\n",
    "   stress-test the CPU.\n",
    "\n",
    "   - THE TABLE ANALYSIS: Look at the `mcf` (Combinatorial optimisation) row for\n",
    "     the Opteron X4 processor. Its CPI is a disastrous 10.00. The note points \n",
    "     out this is due to \"High cache miss rate\". thE cpu kept looking for data\n",
    "     in its fast local cache, couldn't find it, and had to wait idly while data\n",
    "     was fetched from slow RAM.\n",
    "   - THE GEOMETRIC MEAN: To find the overall score across all these wildly \n",
    "     different tasks, they compare the execution times against a \"reference\n",
    "     machine\" to get a ratio, and then use the Geometric Mean to average those\n",
    "     ratios so the math isn't skewed by one outlier.\n",
    "\n",
    "\n",
    "---\n",
    "5. A REAL-WORLD SHOWDOWN: Pentium III vs Pentium 4 (P16)\n",
    "   This final slide is a perfect culmination of everything you've learned. It\n",
    "   compares the SPEC benchmark scores of two processors across different clock\n",
    "   speeds.\n",
    "\n",
    "   - THE MYSTERY: ...\n",
    "   - THE ANSWER: The Pentium 4 included a brand new set of instructions called \n",
    "     the Streaming SIMD Extensions 2 (SSE).\n",
    "   - THE CONNECTION TO THE GOLDEN EQUATION: By updating the ISA to include these\n",
    "     new SSE instructions, the compiler could translate floating-point math\n",
    "     differently. This altered both the Instruction Count and the CPI \n",
    "     specifically for floating-point tasks, drastically lowering the overall\n",
    "     Execution Time for those programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5eb60",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "989f9bf6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35217d97",
   "metadata": {},
   "source": [
    "- ... a MULTIPLEXOR (often abbreviated as MUX) is a combinatorial logic circuit\n",
    "  that selects one of many input signals and forwards it to a single output line\n",
    "  . Think of it as a digitally controlled switch or \"traffic controller\" that\n",
    "  decides which data source gets to use a shared resource at any given moment.\n",
    "\n",
    "  KEY COMPONENTS\n",
    "     A multiplexor consists of three main types of lines:\n",
    "     - DATA INPUTS ($2^n$): The various signal sources that are waiting to be\n",
    "       sent to the output.\n",
    "     - SELECTED LINES ($n$): Control signals used to specify which particular\n",
    "       input should be connected to the output. The number of select lines\n",
    "       ($n$) determines the maximum number of inputs ($2^n$).\n",
    "     - OUTPUT (1): The single line where the selected input data is transmitted.\n",
    "\n",
    "\n",
    "   ROLES IN COMPUTER SYSTEMS\n",
    "      Multiplexors are essential building blocks found throughout a processor's\n",
    "      architecture:\n",
    "      - Arithmetic Logic Unit (ALU): MUXes are used to select which operands \n",
    "        (e.g., from registers or immediate values) are fed into the ALU for a\n",
    "        calculation.\n",
    "      - DATA ROUTING: They manage the flow of data across internal buses, \n",
    "        choosing which component (like memroy or an I/O device) has access to \n",
    "        the bus.\n",
    "      - PROGRAM COUNTER (PC) Logic: Used to select the next instruction address,\n",
    "        deciding between the next sequential address or a jump addresses for \n",
    "        branches.    \n",
    "      - MEMORY ACCESS: MUXes help in addressing specific memory locations and\n",
    "        picking the correct data out of caches.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895763e",
   "metadata": {},
   "source": [
    "- An operand in a computer architecture is the data component of an instruction,\n",
    "  representing the specific value, memory location, or register being \n",
    "  manipulated by an operator (opcode). It acts as the object of an operation\n",
    "  (e.g., in `ADD A, B`, A and B are operands), defining waht data is processed.\n",
    "\n",
    "  KEY DETAILS ABOUT OPERANDS\n",
    "     - ROLE: Operands provide the data needed for arithmetic, logical, or data\n",
    "       transfer operations.\n",
    "     - TYPES: They can be immediate values (constants), register identifiers\n",
    "       (e.g., `EAX`), memory addresses (RAM locations), or labels.\n",
    "     - INSTRUCTION FORMAT: An instruction typically consists of an opcode (what\n",
    "       to do) and one or more operands (what to do it to).\n",
    "     - ADDRESSING MODES: Addressing modes define how the operand is located, \n",
    "       such as directly within the instruction, in a register, or in memory.      "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
